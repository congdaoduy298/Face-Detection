{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT8C-Xi8Rses",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b46d8f7f-effe-4335-a15f-046772b9fbb6"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=e621c0728ccc7684feaaac8e6c5719fe47bb807a211e9d12156d876692337a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FdwGlasSin1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "a169a06b-1aa8-4915-df16-b1aec57dc8fe"
      },
      "source": [
        "# Mount to google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYxa2KijSiuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "347187c2-bd79-4df3-f781-7d0fb6f328e9"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/DeepLearning/FaceNet\\ -\\ Practice"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DeepLearning/FaceNet - Practice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYu7gRFOSi0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "from face_recognition import load_image_file, face_encodings, face_locations, compare_faces\n",
        "\n",
        "DATABASE = \"./data\"\n",
        "\n",
        "names = []\n",
        "known_faces = []\n",
        "for name in os.listdir(DATABASE):\n",
        "  for filename in os.listdir(f\"{DATABASE}/{name}\"):\n",
        "    img = load_image_file(f\"{DATABASE}/{name}/{filename}\")\n",
        "    # Face detection works so good with this data view from the front \n",
        "    locations = face_locations(img)\n",
        "    # Get the largest face in a image\n",
        "    locations.sort(key=lambda x:(x[1]-x[3])*(x[2]-x[0]))\n",
        "    # print(name+filename, locations[-1])\n",
        "    if len(locations) == 0: continue\n",
        "    face_enc = face_encodings(img, [locations[-1]])[0]\n",
        "    known_faces.append(face_enc)\n",
        "    names.append(name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIMBk81_Si4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "82de2d45-685d-4d6e-e369-e86956600edc"
      },
      "source": [
        "!pip install face_detection"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_detection\n",
            "  Downloading https://files.pythonhosted.org/packages/63/aa/97ea9bbb2bacb1b22153ed5eb3877e52df96a03240915382c01006fd73de/face_detection-0.1.4-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from face_detection) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_detection) (1.18.5)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_detection) (0.6.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->face_detection) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->face_detection) (7.0.0)\n",
            "Installing collected packages: face-detection\n",
            "Successfully installed face-detection-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUKVYipdSile",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import face_detection\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os \n",
        " \n",
        "# TOLERANCE = 0.7\n",
        "\n",
        "TOLERANCES = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
        "for n_video, TOLERANCE in enumerate(TOLERANCES):\n",
        "\n",
        "  count = 0\n",
        "  cap = cv2.VideoCapture('./test.mp4')\n",
        "  detector = face_detection.build_detector(\n",
        "          \"DSFDDetector\",\n",
        "          max_resolution=1080\n",
        "      )\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "  out = cv2.VideoWriter(f'out_{n_video}.mp4', fourcc, 30.0, (1280, 720))\n",
        "  labels = [\"Tran Thanh\", \"Truong Giang\", \"Lan Ngoc\", \"Kha Nhu\", \n",
        "            \"Mac Van Khoa\", \"Anh Tu\"]\n",
        "\n",
        "  model = \"cnn\"\n",
        "  names = np.array(names)\n",
        "\n",
        "  while(True):\n",
        "      # Capture frame-by-frame\n",
        "      count += 1 \n",
        "      ret, im = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      t = time.time()\n",
        "\n",
        "      face_loc = face_locations(im, model=model)\n",
        "      encoding_faces = face_encodings(im, face_loc)\n",
        "      print(f\"Detection time: {time.time()- t:.3f}\")\n",
        "\n",
        "      for face_encoding, face_location in zip(encoding_faces, face_loc):\n",
        "        results = compare_faces(known_faces, face_encoding, TOLERANCE)\n",
        "        (top, right, bottom, left) = face_location \n",
        "        name = \"Unknown\"\n",
        "        results = np.array(results)\n",
        "        tmp = 0\n",
        "        if True in results:\n",
        "          count_class = np.zeros(6, dtype=int)\n",
        "          for class_name in names[np.where(results == True)[0]]:\n",
        "            count_class[labels.index(class_name)] += 1\n",
        "          tmp = count_class.max()\n",
        "          # Threshold number of image as same as test image must be\n",
        "          #     greater than 12 (about ~30 images each class)\n",
        "          if tmp >= 12:\n",
        "            name = labels[count_class.argmax()] \n",
        "\n",
        "        cv2.rectangle(im, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "        cv2.putText(im, f'{name}-{tmp}', (left, top), cv2.FONT_HERSHEY_SIMPLEX,  \n",
        "                    1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "      out.write(im)\n",
        "      print(f\"Recognition time: {time.time()- t:.3f}\")\n",
        "\n",
        "\n",
        "  # When everything done, release the capture\n",
        "  cap.release()\n",
        "  out.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92mJAxiVS-4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}